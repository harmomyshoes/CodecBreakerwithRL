{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30a38d1-d0b1-43be-a0a8-c34e74b12719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from CODECbreakCode.AudioMixer import FullTrackAudioMixer\n",
    "import CODECbreakCode.Evaluator as Evaluator\n",
    "from CODECbreakCode.Evaluator import MeasureHAAQIOutput\n",
    "import argparse\n",
    "from Optimiser.config import get_config, normalize_action, denormalize_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41790404-f79c-4c82-8717-e54fdf3e09f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \"Possible clipped samples in output.\")\n",
    "warnings.filterwarnings(\"ignore\",message=\"Warning: input samples dtype is np.float64. Converting to np.float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "679ced6e-b6a9-4bfa-bd5c-b5e3f9313e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocal duration orginal is 17.462666666666667 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Drum duration orginal is 17.462666666666667 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Bass duration orginal is 17.462666666666667 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Other duration orginal is 17.462666666666667 seconds, now is the 8.0,  the audio changing to the MONO\n",
      "Mixing File Load Sucessful\n",
      "Referece_File:/home/codecrack/CodecBreakerwithRL/AudioEX/Reggae/Mixing_Result/Reference_IN_O.wav\n",
      "Referece_MP3File:/home/codecrack/CodecBreakerwithRL/AudioEX/Reggae/Mixing_Result_Mp3_Wav/Reference_IN_O_64kbps.wav\n"
     ]
    }
   ],
   "source": [
    "Reggae_Mixing_Path = '/home/codecrack/CodecBreakerwithRL/AudioEX/Reggae'\n",
    "Reggae_Noise_Generator_MP3 = FullTrackAudioMixer(Reggae_Mixing_Path)\n",
    "#Noise_Generator_MP3.ManipulateInitGAIN([0, 0, 0, 0])\n",
    "Reggae_Referece_File = Reggae_Noise_Generator_MP3.TestDynCompTrack([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"Reference_IN_O.wav\",isNormalised=False,isCompensated=True)\n",
    "print(f\"Referece_File:{Reggae_Referece_File}\")\n",
    "\n",
    "Reggae_Referece_MP3File = Evaluator.Mp3LameLossyCompress(Reggae_Referece_File,64)\n",
    "print(f\"Referece_MP3File:{Reggae_Referece_MP3File}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab23c76-3f76-45d6-90e5-95af2b6d2259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952523970516826"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Reggae_MeasureHAAQI = MeasureHAAQIOutput(Reggae_Referece_MP3File)#Initilize the HAAQI with a permanent reference\n",
    "Reggae_MeasureHAAQI.MeasureHAQQIOutput(Reggae_Referece_MP3File) #Test on how far from itself to itsel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88fd0f5e-7748-496c-ab67-970f9fcec229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "BASE_DIR = \"/home/codecrack/CodecBreakerwithRL/AudioEX/Reggae/Mixing_Result\"\n",
    "TMP_SUBDIR = os.path.join(BASE_DIR, \"tmp\")\n",
    "\n",
    "# make sure it exists once at startup:\n",
    "os.makedirs(TMP_SUBDIR, exist_ok=True)\n",
    "def haaqi_reward_muti_fn(solution: np.ndarray, is_normalised=True) -> float:\n",
    "    if is_normalised:\n",
    "        solution = denormalize_action(solution)\n",
    "#    print(f'solution:{solution}')\n",
    " \n",
    "    # Create a unique temp‐file name\n",
    "    fd, degradated_filename = tempfile.mkstemp(prefix=\"dynC_\", suffix=\".wav\")\n",
    "    os.close(fd)  # we’ll let your compressor write to that path\n",
    "\n",
    "    try:\n",
    "        gener_Audio = Reggae_Noise_Generator_MP3.TestDynCompTrack(solution,degradated_filename,isNormalised=False,isCompensated=True)\n",
    "        gener_Audio_mp3 = Evaluator.Mp3LameLossyCompress(gener_Audio, 64)\n",
    "        score = Reggae_MeasureHAAQI.MeasureHAQQIOutput(gener_Audio_mp3)\n",
    "    finally:\n",
    "        # clean up\n",
    "        try:\n",
    "            os.remove(degradated_filename)\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    return round(1 - score, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d726f73e-c9c9-4840-9132-5d0f5709c25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-26 16:28:12.160194: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-26 16:28:12.210297: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-26 16:28:12.210340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-26 16:28:12.215020: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-26 16:28:12.233928: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-26 16:28:12.882302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-07-26 16:28:14.038592: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "import Optimiser.continous_RL_train_PPO\n",
    "from Optimiser.continous_RL_train_PPO import continous_RL_train_PPO as CRLTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de2acb27-702e-4f6c-a05b-64191788ab70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sub_episodes used for a single param update: 4\n",
      "train_env.batch_size = parallel environment number =  2\n",
      "update_num: 10, eval_intv: 5\n",
      "WARNING:tensorflow:From /home/codecrack/CodecBreakerwithRL/Optimiser/continous_RL_train_PPO.py:141: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/codecrack/CodecBreakerwithRL/Optimiser/continous_RL_train_PPO.py:141: ReplayBuffer.gather_all (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `as_dataset(..., single_deterministic_pass=True)` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: policy_loss=-0.042  value_loss=1807.923  entropy_loss=-0.021  clip_fraction=0.058\n",
      "final reward before udpate: -1000000000.0\n",
      "final reward after udpate: 0.2197\n",
      "updated final_solution= [ 0.0000e+00  2.5000e+00  5.5200e+00  5.0000e+02 -2.2000e-01  1.0000e+00\n",
      "  2.0000e+01  2.7043e+02 -2.7700e+00  1.0000e+01  2.0000e+01  1.0000e+02\n",
      " -2.5440e+01  1.0000e+01  1.0000e+00  1.0000e+02]\n",
      "train_step no.= 0\n",
      "best_solution of this generation= [ 0.0000e+00  2.5000e+00  5.5200e+00  5.0000e+02 -2.2000e-01  1.0000e+00\n",
      "  2.0000e+01  2.7043e+02 -2.7700e+00  1.0000e+01  2.0000e+01  1.0000e+02\n",
      " -2.5440e+01  1.0000e+01  1.0000e+00  1.0000e+02]\n",
      "best step reward= 0.2197\n",
      "avg step reward= 0.11347844\n",
      "act_std: [-3.9000e-01  9.8800e+00  1.9750e+01  4.9482e+02 -3.9000e-01  9.8800e+00\n",
      "  1.9750e+01  4.9482e+02 -3.9000e-01  9.8800e+00  1.9750e+01  4.9482e+02\n",
      " -3.9000e-01  9.8800e+00  1.9750e+01  4.9482e+02]\n",
      "act_mean: [-15.    5.5  10.5 300.  -15.    5.5  10.5 300.  -15.    5.5  10.5 300.\n",
      " -15.    5.5  10.5 300. ]\n",
      "obs_mean: [  0.     1.     5.72 100.     0.     3.04  20.   465.86 -20.9    9.19\n",
      "  13.9  100.   -18.17   5.79  20.   339.39]\n",
      "obs_std: [  0.  10.  20. 500.   0.  10.  20. 500.   0.  10.  20. 500.   0.  10.\n",
      "  20. 500.]\n",
      "best_step_index: [2, 5]\n",
      "until now, best final_solution= [ 0.0000e+00  2.5000e+00  5.5200e+00  5.0000e+02 -2.2000e-01  1.0000e+00\n",
      "  2.0000e+01  2.7043e+02 -2.7700e+00  1.0000e+01  2.0000e+01  1.0000e+02\n",
      " -2.5440e+01  1.0000e+01  1.0000e+00  1.0000e+02] best final_reward= 0.2197\n",
      " \n",
      "Epoch 1: policy_loss=-0.032  value_loss=221.059  entropy_loss=-0.022  clip_fraction=0.017\n",
      "final reward before udpate: 0.2197\n",
      "final reward after udpate: 0.23\n",
      "updated final_solution= [  0.     1.     6.46 197.95 -30.    10.     1.   500.   -30.     1.\n",
      "   1.   218.84  -4.51   1.    20.   100.  ]\n",
      "Epoch 2: policy_loss=-0.028  value_loss=627.534  entropy_loss=-0.022  clip_fraction=0.008\n",
      "final reward before udpate: 0.23\n",
      "final reward after udpate: 0.3732\n",
      "updated final_solution= [-30.    10.    20.   100.   -30.    10.     1.   100.     0.     2.77\n",
      "  20.   100.     0.     1.     1.   500.  ]\n",
      "Epoch 3: policy_loss=-0.028  value_loss=535.582  entropy_loss=-0.021  clip_fraction=0.008\n",
      "final reward before udpate: 0.3732\n",
      "final reward after udpate: 0.383\n",
      "updated final_solution= [  0.    10.    20.   100.   -30.     9.61   1.   100.   -30.    10.\n",
      "   1.   100.   -30.     1.     1.   100.  ]\n",
      "Epoch 4: policy_loss=-0.029  value_loss=593.354  entropy_loss=-0.021  clip_fraction=0.025\n",
      "final reward before udpate: 0.383\n",
      "final reward after udpate: 0.3936\n",
      "updated final_solution= [  0.    10.    17.27 367.21 -30.    10.     1.   105.55   0.    10.\n",
      "  19.39 400.14 -30.    10.     1.   100.  ]\n",
      "Epoch 5: policy_loss=-0.007  value_loss=270.203  entropy_loss=-0.021  clip_fraction=0.000\n",
      "train_step no.= 5\n",
      "best_solution of this generation= [  0.     1.    18.22 500.   -30.    10.     1.   100.   -30.    10.\n",
      "   1.   100.     0.    10.    17.92 100.  ]\n",
      "best step reward= 0.3815\n",
      "avg step reward= 0.18852587\n",
      "act_std: [-3.5000e-01  9.8100e+00  1.9480e+01  4.9320e+02 -5.5000e-01  9.8100e+00\n",
      "  1.9700e+01  4.9159e+02 -8.7000e-01  9.8700e+00  1.9820e+01  4.8828e+02\n",
      " -9.0000e-02  9.8800e+00  1.9630e+01  4.9622e+02]\n",
      "act_mean: [-14.39   5.51  10.39 297.12 -15.61   5.45  10.2  291.46 -15.11   5.62\n",
      "  10.47 299.42 -14.46   5.51  10.86 303.11]\n",
      "obs_mean: [  0.     3.19   3.56 397.45 -30.    10.     1.   100.     0.    10.\n",
      "   1.   488.85   0.     3.19   1.   373.77]\n",
      "obs_std: [  0.  10.  20. 500.   0.  10.  20. 500.   0.  10.  20. 500.   0.  10.\n",
      "  20. 500.]\n",
      "best_step_index: [3, 25]\n",
      "until now, best final_solution= [  0.    10.    17.27 367.21 -30.    10.     1.   105.55   0.    10.\n",
      "  19.39 400.14 -30.    10.     1.   100.  ] best final_reward= 0.3936\n",
      " \n",
      "Epoch 6: policy_loss=-0.014  value_loss=104.136  entropy_loss=-0.021  clip_fraction=0.017\n",
      "Epoch 7: policy_loss=-0.010  value_loss=18.543  entropy_loss=-0.021  clip_fraction=0.042\n",
      "Epoch 8: policy_loss=-0.009  value_loss=58.543  entropy_loss=-0.022  clip_fraction=0.000\n",
      "Epoch 9: policy_loss=0.007  value_loss=97.182  entropy_loss=-0.022  clip_fraction=0.000\n",
      "final_solution= [  0.    10.    17.27 367.21 -30.    10.     1.   105.55   0.    10.\n",
      "  19.39 400.14 -30.    10.     1.   100.  ] final_reward= 0.3936\n"
     ]
    }
   ],
   "source": [
    "trainner = CRLTrain(sub_episode_length=30, sub_episode_num_single_batch=2, env_num=2)\n",
    "trainner.set_environments(haaqi_reward_muti_fn)\n",
    "trainner.train(update_num=10, eval_intv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecbe26a-4124-442a-86df-03c71a20930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Reggae_Noise_Generator_MP3.EraseTheMp3Mixing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afb4ac-7058-4058-acc5-8b8397c1857f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
