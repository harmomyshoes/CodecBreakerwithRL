{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "243e06ab-6026-4a32-97a1-0b99fed4177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.display import Audio\n",
    "\n",
    "import rich\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ast import literal_eval\n",
    "from audiomentations import Gain,Normalize,LoudnessNormalization,AddGaussianSNR,Compose,Limiter,ClippingDistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5830a70-b2a0-4456-905e-8b7fa9336f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_FS = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef1f998-7dc0-45aa-918c-8ab4fd0a548d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestToneEvalClass:\n",
    "    def __init__(self, duration, samplerate, frequency, filefold):\n",
    "        self.samplerate = samplerate\n",
    "        self.frequency = frequency\n",
    "        self.duration = duration\n",
    "        self.filefold = filefold\n",
    "    \n",
    "    def SinWaveGenerator(self):\n",
    "        t = np.linspace(0, self.duration, int(self.duration * self.samplerate), endpoint=False)\n",
    "        sine = np.sin(2 * np.pi * self.frequency * t)\n",
    "        return sine\n",
    "\n",
    "    def Adding_WNSNR(self, snr_db, data):\n",
    "        if(snr_db != 0):\n",
    "            Audio_Transform = AddGaussianSNR(min_snr_db=snr_db,max_snr_db=snr_db,p=1.0)\n",
    "            data = Audio_Transform(data, sample_rate=self.samplerate)\n",
    "        return data\n",
    "\n",
    "    def Add_HummingSNR(self, snr_db, audio_signal, frequencies):\n",
    "        #if amplitudes is None:\n",
    "        # Set default amplitude to 0.5 for all frequencies if not provided\n",
    "        #    amplitudes = [0.5] * len(frequencies)\n",
    "        if (snr_db>0):\n",
    "            originalRMS = self.Calculate_rms(audio_signal)\n",
    "            print(f\"The original level of signal is {originalRMS}\")\n",
    "            noise_RMS = self.Calculate_desired_noise_rms(originalRMS,snr_db)\n",
    "            print(f\"The noise level of signal is {noise_RMS}dB\")\n",
    "            noise_amplitude = self.Convert_decibels_to_amplitude_ratio(noise_RMS)\n",
    "            print(f\"comparing to adding noise with {noise_amplitude}\")\n",
    "\n",
    "            # Create a time array based on the length of the audio signal\n",
    "            t = np.arange(len(audio_signal)) / self.samplerate\n",
    "\n",
    "            # Initialize the new signal as a copy of the original audio signal\n",
    "            new_audio_signal = np.copy(audio_signal)\n",
    "\n",
    "            # Add each sine wave to the audio signal\n",
    "            for freq in frequencies:\n",
    "                sine_wave = noise_RMS * np.sin(2 * np.pi * freq * t)\n",
    "                new_audio_signal += sine_wave\n",
    "            return new_audio_signal\n",
    "        else:\n",
    "            return audio_signal\n",
    "\n",
    "    def Adding_Limiter(self,data,thres_db,attac_time=0.0001,reles_time=0.0001):\n",
    "        if(thres_db != 0):\n",
    "            Audiomentations_Transform = Limiter(min_threshold_db=-thres_db,max_threshold_db=-thres_db,min_attack=attac_time,max_attack=attac_time,min_release=reles_time,max_release=reles_time,threshold_mode=\"relative_to_signal_peak\",p=1.0)\n",
    "#            Audiomentations_Transform = Limiter(min_threshold_db=-thres_db,max_threshold_db=-thres_db,min_attack=0.0005,max_attack=0.0005,min_release=0.05,max_release=0.05,threshold_mode=\"relative_to_signal_peak\",p=1.0)\n",
    "            data = Audiomentations_Transform(data, sample_rate=self.samplerate )\n",
    "        return data\n",
    "        \n",
    "    def Adding_Clipping(self, samples, sample_rate, clipping_rate):\n",
    "        if clipping_rate != 0:\n",
    "            print(\"starting clipping\")\n",
    "            clipping_rate = round(clipping_rate, 1)\n",
    "            lower_percentile_threshold = clipping_rate / 2\n",
    "            lower_threshold, upper_threshold = np.percentile(\n",
    "                samples, [lower_percentile_threshold, 100 - lower_percentile_threshold]\n",
    "            )\n",
    "            samples = np.clip(samples, lower_threshold, upper_threshold)\n",
    "        return samples\n",
    "\n",
    "    \n",
    "    def DropingSamplesByPercentage(self, percentage, data):\n",
    "        if(percentage > 0 and percentage < 1):\n",
    "            num_samples = len(data)\n",
    "            num_samples_to_drop = int(percentage*num_samples)\n",
    "            drop_indices = np.random.choice(num_samples,num_samples_to_drop,replace=False)\n",
    "            remapping_data = data\n",
    "            remapping_data[drop_indices] = 0\n",
    "        return remapping_data\n",
    "    \n",
    "    def DropingSamplesByNum(self, drop_samplenum, data):\n",
    "        if(drop_samplenum > 0):\n",
    "            num_samples = len(data)\n",
    "            drop_indices = np.random.choice(num_samples,drop_samplenum,replace=False)\n",
    "            data[drop_indices] = 0\n",
    "        return data\n",
    "    \n",
    "    def PlotTimeSignal(self,data):\n",
    "        time = np.linspace(0., duration, len(data))  # Time values for each sample \n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.plot(time,data,label=\"Waveform\")\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.ylim(-1.1, 1.1)\n",
    "        plt.title('Waveform of the Audio')\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "\n",
    "    def PlotFFT(self,data):\n",
    "        data = data / np.max(np.abs(data))\n",
    "        window = np.hanning(len(data))  \n",
    "        y_windowed = data * window  \n",
    "        \n",
    "        # Zero-pad to increase FFT resolution\n",
    "        #N = 2**16  # Larger FFT size (e.g., 16384)\n",
    "        fft_result = np.fft.fft(y_windowed, n=len(data))\n",
    "        frequencies = np.fft.fftfreq(len(data), d=1/self.samplerate)\n",
    "        \n",
    "        # Keep only the positive half of the spectrum\n",
    "        half_N = len(data) // 2\n",
    "        fft_magnitude = np.abs(fft_result[:half_N]) / len(data)\n",
    "        fft_magnitude_db = 20 * np.log10(fft_magnitude + 1e-12)\n",
    "        frequencies = frequencies[:half_N]\n",
    "        \n",
    "        # Plot FFT with log scale\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(frequencies, fft_magnitude_db, color='b')\n",
    "        plt.xscale(\"log\")  # Logarithmic frequency axis\n",
    "        plt.xlabel(\"Frequency (Hz)\", fontsize=14)\n",
    "        plt.ylabel(\"Magnitude (dB)\", fontsize=14)\n",
    "        plt.title(\"Enhanced FFT Spectrum (Log Scale)\", fontsize=16)\n",
    "        plt.grid()\n",
    "        plt.ylim(-120, 0)\n",
    "        plt.show()\n",
    "        \n",
    "    def SignalFileGenerator(self, audiodata, filename):\n",
    "        ##by default all the data will be nomalized\n",
    "        Normalize_Transform = Normalize(p=1.0)\n",
    "        audiodata = Normalize_Transform(audiodata,self.samplerate)\n",
    "        write(self.filefold+filename, self.samplerate, audiodata)\n",
    "        return self.filefold+filename\n",
    "\n",
    "    def Mp3MixingFileGenerator(self,audiodata,filename,bitrate=64):\n",
    "        #the single file set to LUFS -14\n",
    "        Lufs_Transform = LoudnessNormalization(min_lufs=-14.0,max_lufs=-14.0,p=1.0)\n",
    "        mixing_data = Lufs_Transform(audiodata, self.samplerate)\n",
    "        tmp_file = self.SignalFileGenerator(mixing_data, filename)\n",
    "        command_out = os.popen(\"sh /home/codecrack/Jnotebook/CODECbreakCode/Audio_LameCompress.sh -a %s -b %s \" %(tmp_file,bitrate)).read()\n",
    "        match = re.search(r\"outputMp3toWavfilepath=\\s*(.+?)\\s+by FFMPEG\", command_out)\n",
    "        if match:\n",
    "            file_path = match.group(1)  # Capture the file path\n",
    "            return file_path\n",
    "        else:\n",
    "            print(\"File path not found in the output.\") \n",
    "            return \"File path not found in the output.\"\n",
    "        \n",
    "        \n",
    "    def Calculate_desired_noise_rms(self,clean_rms, snr):\n",
    "        a = float(snr) / 20\n",
    "        noise_rms = clean_rms / (10**a)\n",
    "        return noise_rms\n",
    "    \n",
    "    def Convert_decibels_to_amplitude_ratio(self,decibels):\n",
    "        return 10 ** (decibels / 20)\n",
    "    \n",
    "    def Calculate_rms(self,samples):\n",
    "        return np.sqrt(np.mean(np.square(samples)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420bc5ce-6ebd-404c-813e-7b92d344ebaa",
   "metadata": {},
   "source": [
    "### testTone Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23381516-f875-41d4-8d5a-d4792aa2d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## duration on second\n",
    "duration = 8\n",
    "samplerate = DEFAULT_FS\n",
    "frequency_Vocal = 240\n",
    "output_fold = '/home/codecrack/Jnotebook/44k1/Sine/'\n",
    "sineTone_Vocal = TestToneEvalClass(duration, samplerate, frequency_Vocal, output_fold)\n",
    "sinewave_Vocal = sineTone_Vocal.SinWaveGenerator()\n",
    "sineTone_Vocal.SignalFileGenerator(sinewave_Vocal,f\"vocals.wav\" )\n",
    "\n",
    "frequency_Drum = 100\n",
    "sineTone_Drum = TestToneEvalClass(duration, samplerate, frequency_Drum, output_fold)\n",
    "sinewave_Drum = sineTone_Drum.SinWaveGenerator()\n",
    "sineTone_Drum.SignalFileGenerator(sinewave_Drum,f\"drums.wav\" )\n",
    "\n",
    "frequency_Guitar = 1200\n",
    "sineTone_Guitar = TestToneEvalClass(duration, samplerate, frequency_Guitar, output_fold)\n",
    "sinewave_Guitar = sineTone_Guitar.SinWaveGenerator()\n",
    "sineTone_Guitar.SignalFileGenerator(sinewave_Guitar,f\"other.wav\" )\n",
    "\n",
    "frequency_Bass = 330\n",
    "sineTone_Bass = TestToneEvalClass(duration, samplerate, frequency_Bass, output_fold)\n",
    "sinewave_Bass = sineTone_Bass.SinWaveGenerator()\n",
    "sineTone_Bass.SignalFileGenerator(sinewave_Bass,f\"bass.wav\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f83e284-ad8f-4a52-90ae-2c015d1acfe6",
   "metadata": {},
   "source": [
    "## Track Test Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4ee2b7-3118-4850-bad1-07ddce5ae44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/codecrack/Jnotebook/')\n",
    "from CODECbreakCode.AudioMixer import FullTrackAudioMixer\n",
    "import CODECbreakCode.Evaluator as Evaluator\n",
    "from CODECbreakCode.Evaluator import MeasureHAAQIOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b778c50-d714-4ebb-9aa7-6b6c7dc9a944",
   "metadata": {},
   "source": [
    "## Gospel Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f321c6-7483-4e4e-aa1f-d4a5003090f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocal duration orginal is 75.73730158730159 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Drum duration orginal is 75.73730158730159 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Bass duration orginal is 75.73730158730159 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Other duration orginal is 75.73730158730159 seconds, now is the 8.0,  the audio changing to the MONO\n",
      "Mixing File Load Sucessful\n",
      "The mixing ouput in the RMS, Vocal: -16.12dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Drum: -18.87dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Bass: -20.83dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Other: -25.72dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The pre-mixing ouput(no Normalize, no -14 LUFS) in the RMS, Total: -13.2dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "It is Unormailzed on each track when mixing\n",
      "AfterCompensation, The mixing ouput in the RMS, Vocal: -16.12dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Drum: -18.87dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Bass: -20.83dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Other: -25.72dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "After LUFS&Peak Normlizaiton, the mixing ouput in the RMS, Total: -11.35dB, Clipping Ratio&Cliped Num: (0.0, 12)\n",
      "Referece_File:/home/codecrack/Jnotebook/44k1/Gospel/Mixing_Result/Reference_IN_test.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Referece_MP3File:/home/codecrack/Jnotebook/44k1/Gospel/Mixing_Result_Mp3_Wav/Reference_IN_test_64kbps.wav\n"
     ]
    }
   ],
   "source": [
    "Mixing_Path = '/home/codecrack/Jnotebook/44k1/Gospel'\n",
    "Noise_Generator_MP3 = FullTrackAudioMixer(Mixing_Path, StartingTime=8)\n",
    "#Noise_Generator_MP3.ManipulateInitGAIN([-9, -10, 10, -10]) #this loudness adjust only incase the result want to check the cirtain level situation\n",
    "Referece_File = Noise_Generator_MP3.TestNoisedFullTrack([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"Reference_IN_test.wav\",isNormalised=False,isCompensated=True)\n",
    "\n",
    "#Referece_File = Noise_Generator_MP3.TestNoisedFullTrack([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"Reference_IN_Orig.wav\",isNormalised=False,isCompensated=True)\n",
    "\n",
    "print(f\"Referece_File:{Referece_File}\")\n",
    "\n",
    "Referece_MP3File = Evaluator.Mp3LameLossyCompress(Referece_File,64)\n",
    "print(f\"Referece_MP3File:{Referece_MP3File}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f982c9-b177-4e86-90dd-f947d5311c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993324166236273"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialise the HAAQI Function\n",
    "MeasureHAAQI = MeasureHAAQIOutput(Referece_MP3File)#Initilize the HAAQI with a permanent reference\n",
    "MeasureHAAQI.MeasureHAQQIOutput(Referece_MP3File) #Test on how far from itself to itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8684ab-0b8d-480b-abb7-5014705dd994",
   "metadata": {},
   "source": [
    "### Observation Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482c3688-fa6e-4734-9d5c-d9eeb582bb35",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Gospel track \n",
    "if only vocal track has permutation, all other track not do anything. The limiter do degraded the quality in the conditions. \n",
    "[50, 3.0 ,0] in score 0.818,and\n",
    "[50,3.0,3.0] in score 0.526\n",
    "Also the clipping and whitenoise in other tracks saw no change on the trends of limitrer.\n",
    "[50, 3.0, 0.0, 50, 3.0, 0.0, 50, 3.0, 0.0, 50, 3.0, 0.0] 0.72,\n",
    "[50, 3.0, 3.0, 50, 3.0, 0.0, 50, 3.0, 0.0, 50, 3.0, 0.0] 0.491\n",
    "\n",
    "##### Eventually, it is become a war of loudness, Which is the real reason the system goes wrong\n",
    "The case is most strange is here:\n",
    "[0, 0.0, 3.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0] 0.56\n",
    "[0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 0.0, 0, 0.0, 3.0] 0.75 adding the limiter on guitar and drum excatlly boost the score.\n",
    "[0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0] 0.77 adding the bass limiter is not big deal,onlu 0.02 change.\n",
    "[0, 0.0, 6.0, 0, 0.0, 3.0, 0, 0.0, 0.0, 0, 0.0, 3.0] 0.73 even then limiter keep adding up + 3dB, the metric believe it is only small degradation.\n",
    "[0, 0.0, 15.0, 0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0] 0.58, 0 is equal to put the vocal limiter on -15dB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547e0d98-2235-4ab3-8493-cfe8645672b4",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479fa109-bac8-4acc-99bd-895eb34bd944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mixing ouput in the RMS, Vocal: -16.12dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Drum: -18.94dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Bass: -20.85dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Other: -25.74dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The pre-mixing ouput(no Normalize, no -14 LUFS) in the RMS, Total: -13.21dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "It is Unormailzed on each track when mixing\n",
      "AfterCompensation, The mixing ouput in the RMS, Vocal: -16.12dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Drum: -18.87dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Bass: -20.83dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Other: -25.72dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "After LUFS&Peak Normlizaiton, the mixing ouput in the RMS, Total: -11.35dB, Clipping Ratio&Cliped Num: (0.0, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAAQI Result is 0.5432479775377717\n"
     ]
    }
   ],
   "source": [
    "#solution = [0, 0.0, 6.0, 0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0] \n",
    "solution = [0, 0.0, 0.0, 0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0] \n",
    "#without round the score\n",
    "\n",
    "v_int_noise = solution[0]\n",
    "v_float_clippingper = solution[1]\n",
    "v_float_IIdynamic = solution[2]\n",
    "d_int_noise = solution[3]\n",
    "d_float_clippingper = solution[4]\n",
    "d_float_IIdynamic = solution[5]\n",
    "b_int_noise = solution[6]\n",
    "b_float_clippingper = solution[7]\n",
    "b_float_IIdynamic = solution[8]\n",
    "o_int_noise = solution[9]\n",
    "o_float_clippingper = solution[10]\n",
    "o_float_IIdynamic = solution[11]    \n",
    "filename = f'audio_mixing_FT_HAQI_V_SNR_{v_int_noise}.0_CP_{v_float_clippingper}_IITH_{v_float_IIdynamic}_D_SNR_{d_int_noise}.0_CP_{d_float_clippingper}_IITH_{d_float_IIdynamic}_B_SNR_{b_int_noise}.0_CP_{b_float_clippingper}_IITH_{b_float_IIdynamic}_O_SNR_{o_int_noise}.0_CP_{o_float_clippingper}_IITH_{o_float_IIdynamic}.wav'\n",
    "Gener_Audio = Noise_Generator_MP3.TestNoisedFullTrack(solution,filename,isNormalised=False,isCompensated=True)\n",
    "Gener_Audio_mp3 = Evaluator.Mp3LameLossyCompress(Gener_Audio,64)\n",
    "    #print(Gener_Audio)\n",
    "score = MeasureHAAQI.MeasureHAQQIOutput(Gener_Audio_mp3)\n",
    "print(f\"HAAQI Result is {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea84a8-d5ba-4d7b-9155-3e55df74d16c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Reggae Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63d5725-09c6-460e-a0bc-b7aeab921c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocal duration orginal is 17.46267573696145 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Drum duration orginal is 17.46267573696145 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Bass duration orginal is 17.46267573696145 seconds, now is the 8.0, the audio changing to the MONO\n",
      "Other duration orginal is 17.46267573696145 seconds, now is the 8.0,  the audio changing to the MONO\n",
      "Mixing File Load Sucessful\n",
      "The mixing ouput in the RMS, Vocal: -17.98dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Drum: -14.85dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Bass: -19.59dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Other: -32.89dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The pre-mixing ouput(no Normalize, no -14 LUFS) in the RMS, Total: -12.21dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "It is Unormailzed on each track when mixing\n",
      "AfterCompensation, The mixing ouput in the RMS, Vocal: -17.98dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Drum: -14.85dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Bass: -19.59dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Other: -32.89dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "After LUFS&Peak Normlizaiton, the mixing ouput in the RMS, Total: -9.11dB, Clipping Ratio&Cliped Num: (0.0020011337868480724, 706)\n",
      "Referece_File:/home/codecrack/Jnotebook/44k1/Reggea/Mixing_Result/Reference_IN_Test.wav\n",
      "Referece_MP3File:/home/codecrack/Jnotebook/44k1/Reggea/Mixing_Result_Mp3_Wav/Reference_IN_Test_64kbps.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n"
     ]
    }
   ],
   "source": [
    "Mixing_Path = '/home/codecrack/Jnotebook/44k1/Reggea'\n",
    "Noise_Generator_MP3 = FullTrackAudioMixer(Mixing_Path)\n",
    "#Noise_Generator_MP3.ManipulateInitGAIN([-10, -10, 10, -10]) #this loudness adjust only incase the result want to check the cirtain level situation\n",
    "Referece_File = Noise_Generator_MP3.TestNoisedFullTrack([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"Reference_IN_Test.wav\",isNormalised=False,isCompensated=True)\n",
    "#Noise_Generator_MP3.ManipulateInitGAIN([0, 0, 0, 0])\n",
    "#Referece_File = Noise_Generator_MP3.TestNoisedFullTrack([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"Reference_IN_Orig.wav\",isNormalised=False,isCompensated=True)\n",
    "print(f\"Referece_File:{Referece_File}\")\n",
    "\n",
    "Referece_MP3File = Evaluator.Mp3LameLossyCompress(Referece_File,64)\n",
    "print(f\"Referece_MP3File:{Referece_MP3File}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b2e4385-7604-4bad-a7a8-cd558696c758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9972462823059598"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## initialise the HAAQI Function\n",
    "MeasureHAAQI = MeasureHAAQIOutput(Referece_MP3File)#Initilize the HAAQI with a permanent reference\n",
    "MeasureHAAQI.MeasureHAQQIOutput(Referece_MP3File) #Test on how far from itself to itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a487e4d3-8a09-4d7f-b8d7-aec6c0c3ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mixing ouput in the RMS, Vocal: -18.09dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Drum: -14.97dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Bass: -19.62dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The mixing ouput in the RMS, Other: -32.92dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "The pre-mixing ouput(no Normalize, no -14 LUFS) in the RMS, Total: -12.31dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "It is Unormailzed on each track when mixing\n",
      "AfterCompensation, The mixing ouput in the RMS, Vocal: -17.98dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Drum: -14.85dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Bass: -19.59dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "AfterCompensation, The mixing ouput in the RMS, Other: -32.89dB, Clipping Ratio&Cliped Num: (0.0, 0)\n",
      "After LUFS&Peak Normlizaiton, the mixing ouput in the RMS, Total: -9.13dB, Clipping Ratio&Cliped Num: (0.0013180272108843536, 465)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.11/site-packages/pyloudnorm/normalize.py:62: UserWarning: Possible clipped samples in output.\n",
      "  warnings.warn(\"Possible clipped samples in output.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAAQI Result is 0.7957607628681589\n"
     ]
    }
   ],
   "source": [
    "solution = [0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0] \n",
    "\n",
    "#without round the score\n",
    "\n",
    "v_int_noise = solution[0]\n",
    "v_float_clippingper = solution[1]\n",
    "v_float_IIdynamic = solution[2]\n",
    "d_int_noise = solution[3]\n",
    "d_float_clippingper = solution[4]\n",
    "d_float_IIdynamic = solution[5]\n",
    "b_int_noise = solution[6]\n",
    "b_float_clippingper = solution[7]\n",
    "b_float_IIdynamic = solution[8]\n",
    "o_int_noise = solution[9]\n",
    "o_float_clippingper = solution[10]\n",
    "o_float_IIdynamic = solution[11]    \n",
    "filename = f'audio_mixing_FT_HAQI_V_SNR_{v_int_noise}.0_CP_{v_float_clippingper}_IITH_{v_float_IIdynamic}_D_SNR_{d_int_noise}.0_CP_{d_float_clippingper}_IITH_{d_float_IIdynamic}_B_SNR_{b_int_noise}.0_CP_{b_float_clippingper}_IITH_{b_float_IIdynamic}_O_SNR_{o_int_noise}.0_CP_{o_float_clippingper}_IITH_{o_float_IIdynamic}.wav'\n",
    "Gener_Audio = Noise_Generator_MP3.TestNoisedFullTrack(solution,filename,isNormalised=False,isCompensated=True)\n",
    "Gener_Audio_mp3 = Evaluator.Mp3LameLossyCompress(Gener_Audio,64)\n",
    "    #print(Gener_Audio)\n",
    "score = MeasureHAAQI.MeasureHAQQIOutput(Gener_Audio_mp3)\n",
    "print(f\"HAAQI Result is {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c242712b-6f60-4018-ab1e-ea8e353e6a8c",
   "metadata": {},
   "source": [
    "##### Observation Log\n",
    "\n",
    "Again in Reggea Track:\n",
    "[50, 3.0, 0.0, 50, 3.0, 0.0, 50, 3.0, 0.0, 50, 3.0, 0.0]:  0.689, no limiter \n",
    "[50, 3.0, 3.0, 50, 3.0, 3.0, 50, 3.0, 3.0, 50, 3.0, 3.0] : 0.549, all limiter\n",
    "[50, 3.0, 0.0, 50, 3.0, 3.0, 50, 3.0, 3.0, 50, 3.0, 3.0]: 0.491, all limiter except vocal,\n",
    "[50, 3.0, 3.0, 50, 3.0, 0.0, 50, 3.0, 0.0, 50, 3.0, 0.0]: 0.562, only vocal limiter,\n",
    "But \"limiter balance\" seems not the single explain here, the latter case vocal still not balance but the score is discrepency.\n",
    "\n",
    "In the only limiter Model\n",
    "[0, 0.0, 3.0, 0, 0.0, 0.0, 0, 0.0, 0.0, 0, 0.0, 0.0]: 0.721 only vocal\n",
    "[0, 0.0, 0.0, 0, 0.0, 3.0, 0, 0.0, 0.0, 0, 0.0, 0.0]: 0.646 only drum\n",
    "[0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 0.0, 0, 0.0, 0.0]: 0.646 only drum and vocal\n",
    "[0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0, 0, 0.0, 3.0]: 0.795"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472e901e-c02f-49bc-bbc1-af3f290d9f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
